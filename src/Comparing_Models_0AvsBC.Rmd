---
title: "Comparing Models: 0A vs BC"
author: "Christopher Morano"
date: "September 20, 2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(randomForest)
library(fastAdaboost)
library(xgboost)
library(caret)
library(lime)
library(pROC)
library(printr)
```

In this document, I will compare the accuracy, sensitivity, specificity, and AUC of a random forest model, an adaboost model, and an XGBoost model.  

First we need to prepare our data set:

```{r}
Aug_med <- read_csv('../data/Med_data_Aug21.csv', col_types=list("Day4"=col_character(), 
                                                                 "Day6"=col_character(),
                                                                 "Day7"=col_character()))
#Let's take the first 7 days of medical results:
Aug_med_day7 <- select(Aug_med, ID:Day7)
Aug_med_0AvsBC <- Aug_med_day7
Aug_med_0AvsBC[Aug_med_0AvsBC$Result2016 %in% c("B", "C"),]$Result2016 <- "BC"
Aug_med_0AvsBC[Aug_med_0AvsBC$Result2016 %in% c("0", "A")]$Result2016 <- "OA"
Aug_med_0AvsBC$Result2016 <- factor(Aug_med_0AvsBC$Result2016)

#Making the data tall:
Aug_med_0AvsBC.tall.7 <- gather(select(Aug_med_0AvsBC, ID, Result2016, Day1:Day7), day, result, Day1:Day7) %>% 
  filter(!is.na(result)) %>% 
  arrange(ID)

head(Aug_med_0AvsBC.tall.7)
```

```{r}
#Replacing non-numeric variables, converting to numeric:
set.seed(1313)
Aug_med_0AvsBC.tall.7$result[Aug_med_0AvsBC.tall.7$result == '<10'] <- round(runif(12, 1, 9))
Aug_med_0AvsBC.tall.7$result[Aug_med_0AvsBC.tall.7$result == '>30000'] <- '30001'
Aug_med_0AvsBC.tall.7$result <- as.numeric(Aug_med_0AvsBC.tall.7$result)

#Summarizing the results:
Aug_med_0AvsBC.sum.7 <- Aug_med_0AvsBC.tall.7 %>% 
  group_by(ID) %>% 
  summarize(num_of_results=n(),
            min_result=min(result),
            mean_result=mean(result),
            max_result=max(result),
            var_result=var(result),
            diff_of_last_and_max=ifelse(num_of_results==1, NA, max_result-result[num_of_results]),
            diff_of_last_and_min=ifelse(num_of_results==1, NA, result[num_of_results]-min_result),
            Result_2016=factor(names(which.max(table(Result2016)))))

#removing cases with only 1 result:
Aug_med_0AvsBC.sum.7.2 <- Aug_med_0AvsBC.sum.7 %>% 
  filter(num_of_results > 1)

write_csv(Aug_med_0AvsBC.sum.7.2, 'Med_Data_Shiny/data/med_data.0AvsBC.csv')
head(Aug_med_0AvsBC.sum.7.2)
```

Now let's shuffle the data and create a training and test set:

```{r}
set.seed(1315)
Aug_med_0AvsBC.sum.7.2 <- sample_frac(Aug_med_0AvsBC.sum.7.2)  #1040 rows

#training and test sets:
n <- round(nrow(Aug_med_0AvsBC.sum.7.2))
Aug_med_0AvsBC.sum.7.2.train <- Aug_med_0AvsBC.sum.7.2[1:(n*.75),]
Aug_med_0AvsBC.sum.7.2.test <- Aug_med_0AvsBC.sum.7.2[((n*.75)+1):n,]
```

Running a Random Forest Model:

```{r}
(Aug_med.0AvsBC.rf <- randomForest(Result_2016 ~ max_result +
             diff_of_last_and_max + diff_of_last_and_min, data=Aug_med_0AvsBC.sum.7.2.train,
             xtest=select(Aug_med_0AvsBC.sum.7.2.test, max_result, 
             diff_of_last_and_max, diff_of_last_and_min), ytest=Aug_med_0AvsBC.sum.7.2.test$Result_2016,
             maxnodes = 200, type='prob', importance=TRUE, proximity = TRUE, keep.forest=TRUE, mtry=2))
```

That's really good.  Let's look at the ROC curve for that one:

```{r}
Aug_med.0AvsBC.pred.rf <- predict(Aug_med.0AvsBC.rf, Aug_med_0AvsBC.sum.7.2.test)
Aug_med.0AvsBC.mroc.rf <- roc(ifelse(Aug_med_0AvsBC.sum.7.2.test$Result_2016 == "0", 1, 0),
                           (as.numeric(Aug_med.0AvsBC.pred.rf)-1), plot=TRUE)
```

```{r}
(Aug_med.0AvsBC.rf.auc <- auc(ifelse(Aug_med_0AvsBC.sum.7.2.test$Result_2016 == "0", 1, 0), (as.numeric(Aug_med.0AvsBC.pred.rf)-1)))
```

```{r}
(Aug_med.0AvsBC.rf.coords <- coords(Aug_med.0AvsBC.mroc.rf, .9, "threshold", ret=c("sensitivity","specificity","ppv","npv")))
```

Let's try the same with Adaboost:

```{r}
#adaboost does not like tibbles!  Needed to chage the data to `data.frame`:
Aug_med.0AvsBC.ada <- adaboost(Result_2016 ~ max_result + diff_of_last_and_max + diff_of_last_and_min,
                               data=data.frame(Aug_med_0AvsBC.sum.7.2.train), nIter=50)

Aug_med.0AvsBC.pred.ada <- predict(Aug_med.0AvsBC.ada, Aug_med_0AvsBC.sum.7.2.test)
confusionMatrix(Aug_med.0AvsBC.pred.ada$class, Aug_med_0AvsBC.sum.7.2.test$Result_2016)
```

```{r}
Aug_med.0AvsBC.mroc.ada <- roc(as.numeric(Aug_med_0AvsBC.sum.7.2.test$Result_2016)-1,
                               as.numeric(Aug_med.0AvsBC.pred.ada$class)-1, plot=TRUE)
```

```{r}
(Aug_med.0AvsBC.ada.auc <- auc(ordered(Aug_med_0AvsBC.sum.7.2.test$Result_2016),
                               ordered(Aug_med.0AvsBC.pred.ada$class)))
```

```{r}
(Aug_med.0AvsBC.ada.coords <- coords(Aug_med.0AvsBC.mroc.ada, .9, "threshold", ret=c("sensitivity","specificity","ppv","npv")))
```

And finally, let's try XGBoost:

```{r}
#selecting the features:
Aug_med_0AvsBC.train_X <- Aug_med_0AvsBC.sum.7.2.train %>% 
  select(max_result, diff_of_last_and_max, diff_of_last_and_min)
Aug_med_0AvsBC.train_y <- Aug_med_0AvsBC.sum.7.2.train$Result_2016

Aug_med_0AvsBC.test_X <- Aug_med_0AvsBC.sum.7.2.test %>% 
  select(max_result, diff_of_last_and_max, diff_of_last_and_min)
Aug_med_0AvsBC.test_y <- Aug_med_0AvsBC.sum.7.2.test$Result_2016

#converting X's to matrices and y's to 0's & 1's (for 0 and ABC, respectively):
Aug_med_0AvsBC.train_X.xgb <- model.matrix(~.-1, data=Aug_med_0AvsBC.train_X)
Aug_med_0AvsBC.test_X.xgb <- model.matrix(~.-1, data=Aug_med_0AvsBC.test_X)

Aug_med_0AvsBC.train_y.xgb <- abs(as.numeric(Aug_med_0AvsBC.train_y) -2)
Aug_med_0AvsBC.test_y.xgb <- abs(as.numeric(Aug_med_0AvsBC.test_y) -2)
```

```{r}
#setting the paramaters:
param       = list("objective" = "binary:logistic", # multi class classification
              "eval_metric" = "auc",  	 # evaluation metric 
              "max_depth" = 3,    		 # maximum depth of tree 
              "eta" = 0.5,    			 # step size shrinkage 
              "gamma" = 1,    			 # minimum loss reduction 
              "subsample" = 0.5,    		 # part of data instances to grow tree 
              "colsample_bytree" = 1, 		 # subsample ratio of columns when constructing each tree 
              "min_child_weight" = 2  		 # minimum sum of instance weight needed in a child 
              )
```

```{r}
set.seed(1313)
Aug_med.0AvsBC.xgb = xgboost(
		param=param,
		data = Aug_med_0AvsBC.train_X.xgb,
		label = Aug_med_0AvsBC.train_y.xgb,
		nrounds=150)

Aug_med.0AvsBC.pred.xgb <- predict(Aug_med.0AvsBC.xgb, Aug_med_0AvsBC.test_X.xgb)
confusionMatrix(round(Aug_med.0AvsBC.pred.xgb), Aug_med_0AvsBC.test_y.xgb)
```

```{r}
Aug_med.0AvsBC.mroc.xgb <- roc(Aug_med_0AvsBC.test_y.xgb,
                               round(Aug_med.0AvsBC.pred.xgb), plot=TRUE)
```

```{r}
(Aug_med.0AvsBC.xgb.auc <- auc(Aug_med_0AvsBC.test_y.xgb,
    round(Aug_med.0AvsBC.pred.xgb)))
```

```{r}
(Aug_med.0AvsBC.xgb.coords <- coords(Aug_med.0AvsBC.mroc.xgb, .9, "threshold", ret=c("sensitivity","specificity","ppv","npv")))
```

```{r}
#this was run 2nd:
model_outputs <- read_csv('../results/model_outputs.csv')

model_outputs.0AvsBC <- tibble(Model=rep('0 vs ABC', 3),
                        Algorithm=c('Random Forest', 'Adaboost', 'XGBoost'),
                        AUC=c(Aug_med.0AvsBC.rf.auc[1], Aug_med.0AvsBC.ada.auc[1], Aug_med.0AvsBC.xgb.auc[1]),
                        Sensitivity=c(Aug_med.0AvsBC.rf.coords[[1]], Aug_med.0AvsBC.ada.coords[[1]],
                                      Aug_med.0AvsBC.xgb.coords[[1]]),
                        Specificity=c(Aug_med.0AvsBC.rf.coords[[2]], Aug_med.0AvsBC.ada.coords[[2]],
                                      Aug_med.0AvsBC.xgb.coords[[2]]), 
                        Pos_Pred_Value=c(Aug_med.0AvsBC.rf.coords[[3]], Aug_med.0AvsBC.ada.coords[[3]],
                                      Aug_med.0AvsBC.xgb.coords[[3]]),
                        Neg_Pred_Value=c(Aug_med.0AvsBC.rf.coords[[4]], Aug_med.0AvsBC.ada.coords[[4]],
                                      Aug_med.0AvsBC.xgb.coords[[4]]))

model_outputs <- rbind(model_outputs, model_outputs.0AvsBC)

write_csv(model_outputs, '../results/model_outputs.csv')
```

In order to run `lime` in Shiny, I need the model to be trained using the `caret` package instead of `randomForest`.  Let's do that and make sure I'm getting similar results:

```{r}
#what I'm running in randomForest:
(Aug_med.0AvsBC.rf <- randomForest(Result_2016 ~ max_result +
             diff_of_last_and_max + diff_of_last_and_min, data=Aug_med_0AvsBC.sum.7.2.train,
             xtest=select(Aug_med_0AvsBC.sum.7.2.test, max_result, 
             diff_of_last_and_max, diff_of_last_and_min), ytest=Aug_med_0AvsBC.sum.7.2.test$Result_2016,
             maxnodes = 200, type='prob', importance=TRUE, proximity = TRUE, keep.forest=TRUE))
```

```{r}
Aug_med_0AvsBC.caret.rf <- caret::train(Result_2016 ~ max_result + diff_of_last_and_max + diff_of_last_and_min,
             data=Aug_med_0AvsBC.sum.7.2.train, method = "rf", trControl = trainControl(classProbs = TRUE))

explainer <- lime(Aug_med_0AvsBC.sum.7.2.train, Aug_med_0AvsBC.caret.rf, 
bin_continuous = FALSE, n_permutations = 100)

explanation <- lime::explain(Aug_med_0AvsBC.sum.7.2.train[1,], explainer, n_labels=1, n_features=3)

windowsFonts(Times=windowsFont("TT Times New Roman"))
plot_features(explanation)
```

```{r}
pred <- predict(Aug_med_0AvsBC.caret.rf, Aug_med_0AvsBC.sum.7.2.test[1,], "prob")

test_data <- select(pred, O, ABC)
test_data <- gather(pred, class, prob)
test_data$class <- factor(test_data$class, levels=c("O", "ABC"))
test_data$prob <- as.numeric(test_data$prob)

ggplot(test_data, aes(x=class, y=prob, fill=class)) +
      geom_col() +
      scale_fill_manual(values=c('green3', 'red3')) +
      labs(title='Probability of the Patient Having the Result 0 or ABC:')

#confusionMatrix(pred, Aug_med_0AvsBC.sum.7.2.test$Result_2016)
```
```{r}
as.data.frame(Aug_med_0AvsBC.caret.rf$finalModel$confusion)

as.tibble(Aug_med_0AvsBC.caret.rf$finalModel$confusion) %>% 
  rename(ABC_pred = ABC, O_pred = O) %>% 
  mutate(Training_Data = c("ABC_true", "O_true")) %>% 
  select(Training_Data, everything())

```